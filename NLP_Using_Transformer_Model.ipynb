{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Natural Language Processing with Transformer Architecture**\n",
        "\n"
      ],
      "metadata": {
        "id": "PM3KlhIlju_H"
      },
      "id": "PM3KlhIlju_H"
    },
    {
      "cell_type": "markdown",
      "source": [
        "import packages and check versions"
      ],
      "metadata": {
        "id": "BcOsowcBkOmX"
      },
      "id": "BcOsowcBkOmX"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "324cf957",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "324cf957",
        "outputId": "61956820-b091-4b32-d344-fe6f22862a2b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Check the current version of TensorFlow.\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "xq4d7B1Ys1xp",
      "metadata": {
        "id": "xq4d7B1Ys1xp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "722aeabb-f957-4f66-f8a5-aa382ce7dd0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.8.0\n",
            "Uninstalling tensorflow-2.8.0:\n",
            "  Would remove:\n",
            "    /usr/local/bin/estimator_ckpt_converter\n",
            "    /usr/local/bin/import_pb_to_tensorboard\n",
            "    /usr/local/bin/saved_model_cli\n",
            "    /usr/local/bin/tensorboard\n",
            "    /usr/local/bin/tf_upgrade_v2\n",
            "    /usr/local/bin/tflite_convert\n",
            "    /usr/local/bin/toco\n",
            "    /usr/local/bin/toco_from_protos\n",
            "    /usr/local/lib/python3.10/dist-packages/tensorflow-2.8.0.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/tensorflow/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled tensorflow-2.8.0\n"
          ]
        }
      ],
      "source": [
        "# Uninstall the current version of TensorFlow.\n",
        "!pip uninstall tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vjXKiizis16l",
      "metadata": {
        "id": "vjXKiizis16l"
      },
      "outputs": [],
      "source": [
        "# Install the desired version of TensorFlow.\n",
        "!pip install tensorflow==2.8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "Nd6vHeh_tCcA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nd6vHeh_tCcA",
        "outputId": "aa49d787-afa7-4d4e-f091-de9ad17fe546"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ],
      "source": [
        "# Verify the TensorFlow version.\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **import libraries**"
      ],
      "metadata": {
        "id": "HrmU_JnUkWId"
      },
      "id": "HrmU_JnUkWId"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "0a2d7f08",
      "metadata": {
        "id": "0a2d7f08"
      },
      "outputs": [],
      "source": [
        "# Importing libraries\n",
        "import os\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c183d44",
      "metadata": {
        "id": "7c183d44"
      },
      "source": [
        "# **Importing Drive**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "d5b50c5d",
      "metadata": {
        "id": "d5b50c5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b093083-563b-43fd-aaac-ed67cb257cb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section\n",
        "\n",
        "> We will load the Nepali text dataset from an Excel file stored in Google Drive. We will then display the first few rows of the DataFrame to get an overview of the data.\n",
        "\n"
      ],
      "metadata": {
        "id": "sGEQAWfmkz2N"
      },
      "id": "sGEQAWfmkz2N"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "xXa2FSpP-eD3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "xXa2FSpP-eD3",
        "outputId": "006ae094-133d-46b9-9d5c-03df2a7ecc4f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        english_sent  \\\n",
              "0  It happened after the death of Saul, when Davi...   \n",
              "1  it happened on the third day, that behold, a m...   \n",
              "2  David said to him, \"Where do you come from?\" H...   \n",
              "3  David said to him, \"How did it go? Please tell...   \n",
              "4  David said to the young man who told him, \"How...   \n",
              "\n",
              "                                         nepali_sent  \n",
              "0  दाऊदले अमालेकीहरूलाई हराएर पछि सिकलग गए। यो शा...  \n",
              "1  तब तेस्रो दिनमा एउटा जवान सैनिक सिकलगमा आयो। त...  \n",
              "2  दाऊदले त्यसलाई सोधे, “तिमी कहाँबाट आयौ?” त्यस ...  \n",
              "3  दाऊदले भने, “मलाई भन, के भयो?” त्यसले भन्यो, “...  \n",
              "4  दाऊदले त्यस सैनिकलाई भने, “तिमीले कसरी जान्यौ ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a3d0dc2-dc1b-4293-ab52-847f03a144fe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english_sent</th>\n",
              "      <th>nepali_sent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>It happened after the death of Saul, when Davi...</td>\n",
              "      <td>दाऊदले अमालेकीहरूलाई हराएर पछि सिकलग गए। यो शा...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>it happened on the third day, that behold, a m...</td>\n",
              "      <td>तब तेस्रो दिनमा एउटा जवान सैनिक सिकलगमा आयो। त...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>David said to him, \"Where do you come from?\" H...</td>\n",
              "      <td>दाऊदले त्यसलाई सोधे, “तिमी कहाँबाट आयौ?” त्यस ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>David said to him, \"How did it go? Please tell...</td>\n",
              "      <td>दाऊदले भने, “मलाई भन, के भयो?” त्यसले भन्यो, “...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>David said to the young man who told him, \"How...</td>\n",
              "      <td>दाऊदले त्यस सैनिकलाई भने, “तिमीले कसरी जान्यौ ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a3d0dc2-dc1b-4293-ab52-847f03a144fe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6a3d0dc2-dc1b-4293-ab52-847f03a144fe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6a3d0dc2-dc1b-4293-ab52-847f03a144fe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2eb58491-4b12-4dd5-8dc3-64171febe52e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2eb58491-4b12-4dd5-8dc3-64171febe52e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2eb58491-4b12-4dd5-8dc3-64171febe52e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "# Specify the path to your Excel file\n",
        "excel_file_path = \"/content/drive/MyDrive/english-nepali.xlsx\"\n",
        "\n",
        "# Read the Excel file, specify the sheet name if needed\n",
        "df = pd.read_excel(excel_file_path)\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "rQCSnNTB-PMJ",
      "metadata": {
        "id": "rQCSnNTB-PMJ"
      },
      "outputs": [],
      "source": [
        "# Drop rows with missing values\n",
        "df.dropna(axis=0, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "0c34fe15",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c34fe15",
        "outputId": "0f2cfaa4-231d-4d16-c987-48d94b5c5e34"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(151923, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "7e52ca62",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e52ca62",
        "outputId": "16016717-390b-447f-a2a2-0b8740d6dbf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 151923 entries, 0 to 151936\n",
            "Data columns (total 2 columns):\n",
            " #   Column        Non-Null Count   Dtype \n",
            "---  ------        --------------   ----- \n",
            " 0   english_sent  151923 non-null  object\n",
            " 1   nepali_sent   151923 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 3.5+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d522f9e0",
      "metadata": {
        "id": "d522f9e0"
      },
      "source": [
        "# **DEFINE PARAMETER**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "6b6e1117",
      "metadata": {
        "id": "6b6e1117"
      },
      "outputs": [],
      "source": [
        "# Tranining Hyperparameters\n",
        "batch_size = 128\n",
        "\n",
        "# Model Hyperparameters\n",
        "embed_dim = 128\n",
        "num_heads = 10\n",
        "latent_dim = 2048\n",
        "vocab_size = 20000\n",
        "sequence_length = 20\n",
        "dropout = 0.2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess Text Data\n",
        "In this section, we will define a function to preprocess the English and Nepali text data. The preprocessing steps include converting text to lowercase, removing URLs, digits, special characters, quotes, extra spaces, and adding [start] and [end] tags to the Nepali sentences."
      ],
      "metadata": {
        "id": "pqWEkd42lQc7"
      },
      "id": "pqWEkd42lQc7"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "4b29d8f7",
      "metadata": {
        "id": "4b29d8f7"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(df):\n",
        "    # Lowercase the characters\n",
        "    df[\"english_sent\"] = df[\"english_sent\"].apply(lambda x : x.lower())\n",
        "    df[\"nepali_sent\"] = df[\"nepali_sent\"].apply(lambda x : x.lower())\n",
        "\n",
        "    # Rmoving URLs\n",
        "    df[\"english_sent\"] = df[\"english_sent\"].apply(lambda x : re.sub(r\"http\\S+\", \"\", x))\n",
        "    df[\"nepali_sent\"] = df[\"nepali_sent\"].apply(lambda x : re.sub(r\"http\\S+\", \"\", x))\n",
        "\n",
        "    # Removing digits\n",
        "    remove_digits = str.maketrans(\"\", \"\",string.digits)\n",
        "    df[\"english_sent\"] = df[\"english_sent\"].apply(lambda x : x.translate(remove_digits))\n",
        "    df[\"nepali_sent\"] = df[\"nepali_sent\"].apply(lambda x : x.translate(remove_digits))\n",
        "    df[\"nepali_sent\"] = df[\"nepali_sent\"].apply(lambda x : re.sub(\"[a-zA-z२३०८१५७९४६]\", \"\", x))\n",
        "\n",
        "    # Remove special characters\n",
        "    special = set(string.punctuation)\n",
        "    df['english_sent'] = df['english_sent'].apply(lambda x : ''.join(ch for ch in x if ch not in special))\n",
        "    df['nepali_sent'] = df['nepali_sent'].apply(lambda x : ''.join(ch for ch in x if ch not in special))\n",
        "\n",
        "    # Remove quotes\n",
        "    df['english_sent'] = df['english_sent'].apply(lambda x: re.sub(\"'\", '', x))\n",
        "    df['nepali_sent'] = df['nepali_sent'].apply(lambda x: re.sub(\"'\", '', x))\n",
        "\n",
        "    # Remove extra spaces\n",
        "    df['english_sent'] = df['english_sent'].apply(lambda x : x.strip())\n",
        "    df['nepali_sent'] = df['nepali_sent'].apply(lambda x : x.strip())\n",
        "    df['english_sent'] = df['english_sent'].apply(lambda x : re.sub(\" +\",\" \",x))\n",
        "    df['nepali_sent'] = df['nepali_sent'].apply(lambda x : re.sub(\" +\",\" \",x))\n",
        "\n",
        "\n",
        "    # Add [start] and [end] tags\n",
        "    df[\"nepali_sent\"] = df[\"nepali_sent\"].apply(lambda x : \"[start] \" + x + \" [end]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "cdf755ff",
      "metadata": {
        "id": "cdf755ff"
      },
      "outputs": [],
      "source": [
        "# Drop rows with Null values\n",
        "df.drop(df[df[\"english_sent\"] == \" \"].index, inplace = True)\n",
        "df.drop(df[df[\"nepali_sent\"] == \"[start]  [end]\"].index, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "e601ba70",
      "metadata": {
        "id": "e601ba70"
      },
      "outputs": [],
      "source": [
        "# Find Sentence Length\n",
        "df[\"eng_sent_length\"] = df[\"english_sent\"].apply(lambda x : len(x.split(' ')))\n",
        "df[\"nepali_sent_length\"] = df[\"nepali_sent\"].apply(lambda x : len(x.split(' ')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "23d916dc",
      "metadata": {
        "id": "23d916dc"
      },
      "outputs": [],
      "source": [
        "def decode_sequence(input_sentence):\n",
        "    nepali_vocab = nepali_vectorization.get_vocabulary()\n",
        "    nepali_index_lookup = dict(zip(range(len(nepali_vocab)), nepali_vocab))\n",
        "    max_decoded_sentence_length = 20\n",
        "\n",
        "    tokenized_input_sentence = eng_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = nepali_vectorization([decoded_sentence])[:, :-1]\n",
        "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
        "\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "        sampled_token = nepali_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "\n",
        "    return decoded_sentence[8:-5] # Removing [start] and [end] tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create and Format Dataset\n",
        "In this section, we will define a function to format the dataset for training. The function will vectorize the English and Nepali sentences and prepare the encoder inputs, decoder inputs, and targets for the sequence-to-sequence model."
      ],
      "metadata": {
        "id": "N2XbLemsleh7"
      },
      "id": "N2XbLemsleh7"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "ce0dfbcf",
      "metadata": {
        "id": "ce0dfbcf"
      },
      "outputs": [],
      "source": [
        "# For creating Dataset\n",
        "def format_dataset(eng, hin):\n",
        "    eng = eng_vectorization(eng)\n",
        "    nepali = nepali_vectorization(hin)\n",
        "    return ({\"encoder_inputs\" : eng, \"decoder_inputs\" : nepali[:, :-1],}, nepali[:, 1:])\n",
        "\n",
        "\n",
        "def make_dataset(df):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((df[\"english_sent\"].values, df[\"nepali_sent\"].values))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElSrzeWxvSZR",
        "outputId": "c9581f06-bc6a-49da-a6a6-2ca830b48f75"
      },
      "id": "ElSrzeWxvSZR",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(151923, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "BaEeTc9_viWR",
        "outputId": "a808a7ae-1f4c-4428-fb03-5bbe6cacb043"
      },
      "id": "BaEeTc9_viWR",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        english_sent  \\\n",
              "0  It happened after the death of Saul, when Davi...   \n",
              "1  it happened on the third day, that behold, a m...   \n",
              "2  David said to him, \"Where do you come from?\" H...   \n",
              "3  David said to him, \"How did it go? Please tell...   \n",
              "4  David said to the young man who told him, \"How...   \n",
              "\n",
              "                                         nepali_sent  eng_sent_length  \\\n",
              "0  दाऊदले अमालेकीहरूलाई हराएर पछि सिकलग गए। यो शा...               25   \n",
              "1  तब तेस्रो दिनमा एउटा जवान सैनिक सिकलगमा आयो। त...               44   \n",
              "2  दाऊदले त्यसलाई सोधे, “तिमी कहाँबाट आयौ?” त्यस ...               22   \n",
              "3  दाऊदले भने, “मलाई भन, के भयो?” त्यसले भन्यो, “...               40   \n",
              "4  दाऊदले त्यस सैनिकलाई भने, “तिमीले कसरी जान्यौ ...               21   \n",
              "\n",
              "   nepali_sent_length  \n",
              "0                  20  \n",
              "1                  32  \n",
              "2                  14  \n",
              "3                  22  \n",
              "4                  12  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3196b584-17cd-47d3-afb5-34a02b1a022d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english_sent</th>\n",
              "      <th>nepali_sent</th>\n",
              "      <th>eng_sent_length</th>\n",
              "      <th>nepali_sent_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>It happened after the death of Saul, when Davi...</td>\n",
              "      <td>दाऊदले अमालेकीहरूलाई हराएर पछि सिकलग गए। यो शा...</td>\n",
              "      <td>25</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>it happened on the third day, that behold, a m...</td>\n",
              "      <td>तब तेस्रो दिनमा एउटा जवान सैनिक सिकलगमा आयो। त...</td>\n",
              "      <td>44</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>David said to him, \"Where do you come from?\" H...</td>\n",
              "      <td>दाऊदले त्यसलाई सोधे, “तिमी कहाँबाट आयौ?” त्यस ...</td>\n",
              "      <td>22</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>David said to him, \"How did it go? Please tell...</td>\n",
              "      <td>दाऊदले भने, “मलाई भन, के भयो?” त्यसले भन्यो, “...</td>\n",
              "      <td>40</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>David said to the young man who told him, \"How...</td>\n",
              "      <td>दाऊदले त्यस सैनिकलाई भने, “तिमीले कसरी जान्यौ ...</td>\n",
              "      <td>21</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3196b584-17cd-47d3-afb5-34a02b1a022d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3196b584-17cd-47d3-afb5-34a02b1a022d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3196b584-17cd-47d3-afb5-34a02b1a022d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b79e949b-7f3e-4bab-99b0-022b600aed47\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b79e949b-7f3e-4bab-99b0-022b600aed47')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b79e949b-7f3e-4bab-99b0-022b600aed47 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Filter, Sample, and Split the Dataset\n",
        "In this section, we will filter the dataset to include sentences of specific length, sample a specified number of records, and split the data into training, validation, and test sets. We will also optionally save the modified datasets."
      ],
      "metadata": {
        "id": "65lC4qJjlvcD"
      },
      "id": "65lC4qJjlvcD"
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "15eb01c8",
      "metadata": {
        "id": "15eb01c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ca997a2-33a5-44c2-b3c2-75172d430418"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data has been processed and split into train, validation, and test sets.\n"
          ]
        }
      ],
      "source": [
        "# Get sentences with specific length 20 or less\n",
        "df = df[df[\"eng_sent_length\"] <= 20]\n",
        "df = df[df[\"nepali_sent_length\"] <= 20]\n",
        "\n",
        "# Define the number of records to sample for training\n",
        "num_records_to_sample = min(4610, len(df))  # Take either 4,610 records or all available records\n",
        "\n",
        "# Sample the specified number of records for training\n",
        "df = df.sample(n=num_records_to_sample, random_state=500)\n",
        "df = df.reset_index(drop=True)\n",
        "\n",
        "# Split the data into train, validation, and test sets\n",
        "train = df.iloc[:4000]  # 4,000 records for training\n",
        "val = df.iloc[4000:4300]  # 300 records for validation\n",
        "test = df.iloc[4300:]  # Remaining records for testing\n",
        "\n",
        "# Optionally, you can save the modified datasets if needed\n",
        "train.to_csv('train.csv', index=False)\n",
        "val.to_csv('val.csv', index=False)\n",
        "test.to_csv('test.csv', index=False)\n",
        "\n",
        "print(\"Data has been processed and split into train, validation, and test sets.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oO_YZGS3t5r_",
      "metadata": {
        "id": "oO_YZGS3t5r_"
      },
      "source": [
        "#**Tokenizing Sentences**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "0ad60b84",
      "metadata": {
        "id": "0ad60b84"
      },
      "outputs": [],
      "source": [
        "# Using TextVectorization to create sentence vectors\n",
        "strip_chars = string.punctuation + \"¿\"\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "\n",
        "\n",
        "def custom_standardization(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n",
        "\n",
        "eng_vectorization = TextVectorization(\n",
        "    max_tokens = vocab_size, output_mode = \"int\", output_sequence_length = sequence_length\n",
        "    )\n",
        "\n",
        "nepali_vectorization = TextVectorization(\n",
        "    max_tokens = vocab_size, output_mode = \"int\", output_sequence_length = sequence_length + 1, standardize=custom_standardization\n",
        ")\n",
        "\n",
        "eng_vectorization.adapt(df[\"english_sent\"].values)\n",
        "nepali_vectorization.adapt(df[\"nepali_sent\"].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "95029bb9",
      "metadata": {
        "id": "95029bb9"
      },
      "outputs": [],
      "source": [
        "# Savng parameters and weights of both vectorizer\n",
        "pickle.dump({'config': eng_vectorization.get_config(),\n",
        "             'weights': eng_vectorization.get_weights()}\n",
        "            , open(\"eng_vectorizer.pkl\", \"wb\"))\n",
        "\n",
        "pickle.dump({'config': nepali_vectorization.get_config(),\n",
        "             'weights': nepali_vectorization.get_weights()}\n",
        "            , open(\"nepali_vectorizer.pkl\", \"wb\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LOaXSBOiuD5e",
      "metadata": {
        "id": "LOaXSBOiuD5e"
      },
      "source": [
        "#**Creating Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "d98872c4",
      "metadata": {
        "id": "d98872c4"
      },
      "outputs": [],
      "source": [
        "train_ds = make_dataset(train)\n",
        "val_ds = make_dataset(val)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Positional Embedding Layer\n",
        "In this section, we define a custom PositionalEmbedding layer, which is a crucial component of the transformer architecture. This layer adds positional information to the token embeddings, allowing the model to understand the order of tokens in the input sequence."
      ],
      "metadata": {
        "id": "YS2IsJEpmWxa"
      },
      "id": "YS2IsJEpmWxa"
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "9b8c02d6",
      "metadata": {
        "id": "9b8c02d6"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_len, vocab_size, embed_dim, **kwargs):\n",
        "        super(PositionalEmbedding, self).__init__(**kwargs)\n",
        "        self.sequence_len = sequence_len\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "        self.token_embedding = layers.Embedding(\n",
        "            input_dim = vocab_size, output_dim = embed_dim\n",
        "        )\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim = sequence_len, output_dim = embed_dim\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start = 0, limit = length, delta = 1)\n",
        "        embedded_tokens = self.token_embedding(inputs)\n",
        "        embedded_positions = self.position_embedding(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer Encoder Layer\n",
        "In this section, we define a custom TransformerEncoder layer, which is an essential component of the transformer architecture. This layer will be used in sequence-to-sequence models for natural language processing (NLP) tasks."
      ],
      "metadata": {
        "id": "D1bLBqowmLyr"
      },
      "id": "D1bLBqowmLyr"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "5815756b",
      "metadata": {
        "id": "5815756b"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, latent_dim, num_heads, dropout,**kwargs):\n",
        "        super(TransformerEncoder, self).__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.dropout = dropout\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads = num_heads, key_dim = embed_dim\n",
        "        )\n",
        "        self.layer_norm1 = layers.LayerNormalization()\n",
        "        self.layer_norm2 = layers.LayerNormalization()\n",
        "        self.layer_ffn = keras.Sequential(\n",
        "            [layers.Dense(latent_dim, activation=\"relu\"),\n",
        "             layers.Dropout(dropout),\n",
        "             layers.Dense(embed_dim),]\n",
        "            )\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask = None):\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\")\n",
        "\n",
        "        attention_output = self.attention(\n",
        "            query = inputs, value = inputs, key = inputs, attention_mask = padding_mask\n",
        "        )\n",
        "        ffn_input = self.layer_norm1(inputs + attention_output)\n",
        "        ffn_output = self.layer_ffn(ffn_input)\n",
        "        return self.layer_norm2(ffn_input + ffn_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer Decoder Layer\n",
        "In this section, we define a custom TransformerDecoder layer, which is a crucial component of the transformer architecture. This layer will be used in sequence-to-sequence models for natural language processing (NLP) tasks."
      ],
      "metadata": {
        "id": "WtTmKTqEmDMC"
      },
      "id": "WtTmKTqEmDMC"
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "b47ce64f",
      "metadata": {
        "id": "b47ce64f"
      },
      "outputs": [],
      "source": [
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, latent_dim, num_heads, sropout,**kwargs):\n",
        "        super(TransformerDecoder, self).__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.dropout = dropout\n",
        "        self.attention1 = layers.MultiHeadAttention(\n",
        "            num_heads = num_heads, key_dim = embed_dim\n",
        "        )\n",
        "        self.attention2 = layers.MultiHeadAttention(\n",
        "            num_heads = num_heads, key_dim = embed_dim\n",
        "        )\n",
        "        self.layer_ffn = keras.Sequential(\n",
        "            [layers.Dense(latent_dim, activation=\"relu\"),\n",
        "             layers.Dropout(dropout),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layer_norm1 = layers.LayerNormalization()\n",
        "        self.layer_norm2 = layers.LayerNormalization()\n",
        "        self.layer_norm3 = layers.LayerNormalization()\n",
        "\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask = None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "\n",
        "        attention_output1 = self.attention1(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
        "        )\n",
        "        out1 = self.layer_norm1(inputs + attention_output1)\n",
        "\n",
        "        attention_output2 = self.attention2(\n",
        "            query = out1, value = encoder_outputs, key = encoder_outputs, attention_mask = padding_mask\n",
        "        )\n",
        "        out2 = self.layer_norm2(out1 + attention_output2)\n",
        "\n",
        "        ffn_output = self.layer_ffn(out2)\n",
        "        return self.layer_norm3(out2 + ffn_output)\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
        "            axis=0,\n",
        "        )\n",
        "        return tf.tile(mask, mult)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building the Transformer Model\n",
        "In this section, we build the transformer model using the previously defined PositionalEmbedding, TransformerEncoder, and TransformerDecoder layers. The model consists of an encoder and a decoder, which are connected to form a sequence-to-sequence model for NLP tasks."
      ],
      "metadata": {
        "id": "aYUuXEtZmieE"
      },
      "id": "aYUuXEtZmieE"
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "777db222",
      "metadata": {
        "id": "777db222"
      },
      "outputs": [],
      "source": [
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
        "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads, dropout,name=\"encoder_1\")(x)\n",
        "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, latent_dim, num_heads, dropout,name=\"decoder_1\")(x, encoded_seq_inputs)\n",
        "x = layers.Dropout(0.4)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
        "\n",
        "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
        "transformer = keras.Model(\n",
        "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Summary\n",
        "In this section, we will generate and display a summary of the transformer model. This summary provides an overview of the model architecture, including the layers, their output shapes, and the number of parameters.\n",
        "\n",
        "# Displaying the Transformer Model Summary"
      ],
      "metadata": {
        "id": "4St6ut65m6Ru"
      },
      "id": "4St6ut65m6Ru"
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "c2aaef41",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2aaef41",
        "outputId": "df466fb5-267e-4821-992c-f106012f5ec2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " positional_embedding_2 (Positi  (None, None, 128)   2562560     ['encoder_inputs[0][0]']         \n",
            " onalEmbedding)                                                                                   \n",
            "                                                                                                  \n",
            " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " encoder_1 (TransformerEncoder)  (None, None, 128)   1186304     ['positional_embedding_2[0][0]'] \n",
            "                                                                                                  \n",
            " model_3 (Functional)           (None, None, 20000)  6988448     ['decoder_inputs[0][0]',         \n",
            "                                                                  'encoder_1[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10,737,312\n",
            "Trainable params: 10,737,312\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "transformer.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Callback Functions and Model Compilation\n",
        "In this section, we define callback functions to monitor the training process and compile the transformer model for training."
      ],
      "metadata": {
        "id": "mt-CkV6GnGvJ"
      },
      "id": "mt-CkV6GnGvJ"
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "--dgJ6CZDLx4",
      "metadata": {
        "id": "--dgJ6CZDLx4"
      },
      "outputs": [],
      "source": [
        "# Defining callback functions\n",
        "early_stopping = EarlyStopping(patience = 5,restore_best_weights=True)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3)\n",
        "\n",
        "# Compiling model\n",
        "transformer.compile(\n",
        "    optimizer = \"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics = [\"accuracy\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inspecting Samples from Datasets\n",
        "In this section, we iterate over TensorFlow datasets (train_ds and val_ds) to inspect some samples of English and Nepali sentences.\n",
        "\n",
        "python"
      ],
      "metadata": {
        "id": "gLIbII3GnWFR"
      },
      "id": "gLIbII3GnWFR"
    },
    {
      "cell_type": "code",
      "source": [
        "# Print some samples from train_ds and val_ds to inspect the data\n",
        "for sample in train_ds.take(5):  # Print the first 5 samples\n",
        "    print(\"English Sentence:\", sample[0][\"encoder_inputs\"].numpy())\n",
        "    print(\"Nepali Sentence:\", sample[1].numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqqqD3HmyNzA",
        "outputId": "593ca7a8-49a5-4526-ab80-3b0b47f64f01"
      },
      "id": "xqqqD3HmyNzA",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "English Sentence: [[ 176    6   48 ...    0    0    0]\n",
            " [3054    2  297 ...    0    0    0]\n",
            " [1871  190   10 ...    0    0    0]\n",
            " ...\n",
            " [  20  597    4 ...    0    0    0]\n",
            " [   2 3098    4 ...    0    0    0]\n",
            " [  25  844 1390 ...    0    0    0]]\n",
            "Nepali Sentence: [[2219   34   75 ...    0    0    0]\n",
            " [ 289 4641    8 ...    0    0    0]\n",
            " [ 458   11 3003 ...    0    0    0]\n",
            " ...\n",
            " [ 428  295 6841 ...    0    0    0]\n",
            " [5271  183 1190 ...    0    0    0]\n",
            " [2607 7638 9021 ...    0    0    0]]\n",
            "English Sentence: [[  23  376 1338 ...    0    0    0]\n",
            " [  83 3427    0 ...    0    0    0]\n",
            " [ 394 1596   23 ...    0    0    0]\n",
            " ...\n",
            " [  38  281 5342 ...    0    0    0]\n",
            " [  35   15   51 ...    0    0    0]\n",
            " [2161   29    4 ...    0    0    0]]\n",
            "Nepali Sentence: [[ 5560  1394     9 ...     0     0     0]\n",
            " [12516   477 11249 ...     0     0     0]\n",
            " [  861   780  2900 ...     0     0     0]\n",
            " ...\n",
            " [12661   234    65 ...     0     0     0]\n",
            " [  412   301   624 ...     0     0     0]\n",
            " [ 1012    27  7514 ...     0     0     0]]\n",
            "English Sentence: [[ 738    8 2121 ...    0    0    0]\n",
            " [1349   13  124 ...    0    0    0]\n",
            " [7101    5 4855 ...    0    0    0]\n",
            " ...\n",
            " [ 313  222    0 ...    0    0    0]\n",
            " [  71   77 1700 ...    0    0    0]\n",
            " [   2 7666    3 ...    0    0    0]]\n",
            "Nepali Sentence: [[ 644 1750   29 ...    0    0    0]\n",
            " [  60 4872   20 ...    0    0    0]\n",
            " [ 810  906  278 ...    0    0    0]\n",
            " ...\n",
            " [ 221    2    0 ...    0    0    0]\n",
            " [   8 3319   37 ...    0    0    0]\n",
            " [  74 1276 1646 ...    0    0    0]]\n",
            "English Sentence: [[   6  224 6939  351    6  209 4889    3  319  224   31 1362    0    0\n",
            "     0    0    0    0    0    0]\n",
            " [  40 1129    5  623 2384    5 5045   20    2 4360   40 4439  139    3\n",
            "     2 1586    0    0    0    0]\n",
            " [   3  239  455 1053    5 1063 1711    2  111   17 6505 7335 5097    5\n",
            "   327  721    0    0    0    0]\n",
            " [  10 3992 6141    4 7800   91  156   85   91    7 4842   20 1322    0\n",
            "     0    0    0    0    0    0]\n",
            " [ 253   20 5390    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]\n",
            " [  27 6243 4864  764   20 2885    4    2  291 4852    0    0    0    0\n",
            "     0    0    0    0    0    0]\n",
            " [  12    8    2  258   15   72  605 1044 1887    7   51  422    0    0\n",
            "     0    0    0    0    0    0]\n",
            " [   5    2 7612   17 4190  857    7    2 3610  235 2029    0    0    0\n",
            "     0    0    0    0    0    0]\n",
            " [1706 6333 2005    4   21  308    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]\n",
            " [ 414    4 2377 5426    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]\n",
            " [1107   27   20 1226    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]\n",
            " [   2  984    4    2 1302 1344  561    9   83   21    2  217    4 6288\n",
            "     0    0    0    0    0    0]\n",
            " [4600 7341    5 4772 7267 2646    4    2 1039   43    2   58   44   43\n",
            "   670    3   12 1416    0    0]\n",
            " [  42   14    8    3  221  251    5 2755   14    2  111   17   78   11\n",
            "   321    3 1195    2  911    0]\n",
            " [  36    2  182    8 5019   15    2 1569  843 6958   17 1575    3 1479\n",
            "   266    2  631 1360  164    0]\n",
            " [ 882 1498 1604    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]\n",
            " [ 497   63    3    2 6960   12    8    2  278   55   72   24 2101    3\n",
            "    11  509    0    0    0    0]\n",
            " [ 296 2507    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]\n",
            " [1200 6059  103    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]\n",
            " [ 402   79   21    2  146   52  188  368   95   64    6  184   52    0\n",
            "     0    0    0    0    0    0]\n",
            " [  39    9  149  685 5670    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]\n",
            " [  12 6657    8    4    6  651 3052    7   91    0    0    0    0    0\n",
            "     0    0    0    0    0    0]\n",
            " [  34  900    3   11    6  342   53   13   26 2154 2771   21   36   14\n",
            "    71  728   12   28  115    0]\n",
            " [ 156    3  227  872  881   10    2 5036    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]\n",
            " [ 708   25  132  372    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]\n",
            " [ 103    3   56   10 2648  691    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]\n",
            " [ 190    4  297  166   11   32 2850    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]\n",
            " [2012  129   31  262 1278    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]\n",
            " [ 260 2284 5561 5131  230 2826    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]\n",
            " [1283   56   21  886    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]\n",
            " [   2  901    4 5229 3671 4876    8    2 2863    7 3773    5 4906  453\n",
            "     0    0    0    0    0    0]\n",
            " [2803  138   83    5 1012  270  527   22  430   50 4616   33 2076   25\n",
            "   525    0    0    0    0    0]]\n",
            "Nepali Sentence: [[  655    26  6103  8563   484   352   524   387   140     2     0     0\n",
            "      0     0     0     0     0     0     0     0]\n",
            " [  189  2455  6830   205   170   282   565  5592    83  6477  3205  1601\n",
            "    349   131  1061   179     0     0     0     0]\n",
            " [ 3086     4  1233  3042   208     6   252  9120  5735     4  8753   800\n",
            "   6004  1418    19     5     2     0     0     0]\n",
            " [ 1438  7736     8  3382   241  1593  8289  8651     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0]\n",
            " [  464   258     3     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0]\n",
            " [ 8416   305 12932    53 10733 12304     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0]\n",
            " [ 6504   538   238   343    50  1970   533    15   188     0     0     0\n",
            "      0     0     0     0     0     0     0     0]\n",
            " [    9 11038   891   197  1194   509 11584   434   399  3143     2     0\n",
            "      0     0     0     0     0     0     0     0]\n",
            " [   12    53  8541    41     6    61     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0]\n",
            " [  893 11783  5884     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0]\n",
            " [  490   582    11    71   198     2     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0]\n",
            " [ 1791   733  7746    22  1090  2363   447    79  2162     0     0     0\n",
            "      0     0     0     0     0     0     0     0]\n",
            " [ 8294  6198  7012     4  8001    77  1057  2303    28  3302   726   128\n",
            "    599    78     2     0     0     0     0     0]\n",
            " [ 1796     4   728 10396    10    25   481   252  7191 10521    79    43\n",
            "     23     2     0     0     0     0     0     0]\n",
            " [  417  5766   491  1016  2107   848   466   352 10151    77   743   720\n",
            "    427 12201     5     0     0     0     0     0]\n",
            " [ 2094  1867     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0]\n",
            " [  361    25  1253   202  1601   401    15    47   255  1264     0     0\n",
            "      0     0     0     0     0     0     0     0]\n",
            " [  270    33 12434    30     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0]\n",
            " [   11  7459    88     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0]\n",
            " [   38    53   521    69  8445   124     5     2    84   362    38    14\n",
            "      3     2     0     0     0     0     0     0]\n",
            " [10064   100     6    39     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0]\n",
            " [12643   567    86   334   106     5     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0]\n",
            " [  326    49   367     2    60 11699   595   784    56  7154    22   146\n",
            "      9    12   137   458     6   199     2     0]\n",
            " [ 3054     8   508  1817   117   170   132     3     2     0     0     0\n",
            "      0     0     0     0     0     0     0     0]\n",
            " [  957    33   560   697     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0]\n",
            " [ 8688     8    17    63  1083     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0]\n",
            " [  200    13  3133   423     2     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0]\n",
            " [  978  3355  1244    57     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0]\n",
            " [  952  3701 11504  8740   112     3     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0]\n",
            " [ 4115    17     3     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0]\n",
            " [    4  7619  2051  6490   268 12709  7726  6735   428    50     5     2\n",
            "      0     0     0     0     0     0     0     0]\n",
            " [ 6392   728   193     4    32  1658   201   159   163  5925    40  3446\n",
            "   6176     7  6393  1984    33  1159     0     0]]\n",
            "English Sentence: [[  12   17   11 ...    0    0    0]\n",
            " [ 773  114    3 ...    0    0    0]\n",
            " [2438    2  569 ...    0    0    0]\n",
            " ...\n",
            " [ 116 7207 1098 ...    0    0    0]\n",
            " [   5   62 1117 ...    0    0    0]\n",
            " [   2  354    4 ...    0    0    0]]\n",
            "Nepali Sentence: [[   52   608  1171 ...     0     0     0]\n",
            " [  294     6   758 ...     0     0     0]\n",
            " [ 6635  9133   129 ...     0     0     0]\n",
            " ...\n",
            " [11433  4941    54 ...     0     0     0]\n",
            " [ 2026 11374  1301 ...     0     0     0]\n",
            " [   72  1051  2182 ...     0     0     0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_ds.element_spec)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFL9oylVyTqF",
        "outputId": "7d7488f6-ca2a-41ca-b6dc-592f43801ffa"
      },
      "id": "xFL9oylVyTqF",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'encoder_inputs': TensorSpec(shape=(None, 20), dtype=tf.int64, name=None), 'decoder_inputs': TensorSpec(shape=(None, 20), dtype=tf.int64, name=None)}, TensorSpec(shape=(None, 20), dtype=tf.int64, name=None))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reducing Layers and Attention Heads, and Training the Model\n",
        "In this section, we reduce the number of layers and attention heads in the transformer model and train it using the training dataset (train_ds) with validation on the validation dataset (val_ds).\n",
        "\n",
        "# Reducing Layers and Attention Heads"
      ],
      "metadata": {
        "id": "R5urxPCInfeB"
      },
      "id": "R5urxPCInfeB"
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "2eifvABPRj92",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eifvABPRj92",
        "outputId": "15c8fd44-66d2-4288-b0e6-faa7293e1243"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "32/32 [==============================] - 103s 3s/step - loss: 3.2458 - accuracy: 0.1164 - val_loss: 3.3817 - val_accuracy: 0.1187 - lr: 0.0010\n",
            "Epoch 2/25\n",
            "32/32 [==============================] - 102s 3s/step - loss: 3.1612 - accuracy: 0.1165 - val_loss: 3.3004 - val_accuracy: 0.1187 - lr: 0.0010\n",
            "Epoch 3/25\n",
            "32/32 [==============================] - 105s 3s/step - loss: 3.0622 - accuracy: 0.1250 - val_loss: 3.2748 - val_accuracy: 0.1345 - lr: 0.0010\n",
            "Epoch 4/25\n",
            "32/32 [==============================] - 103s 3s/step - loss: 2.9339 - accuracy: 0.1496 - val_loss: 3.2828 - val_accuracy: 0.1444 - lr: 0.0010\n",
            "Epoch 5/25\n",
            "32/32 [==============================] - 100s 3s/step - loss: 2.8119 - accuracy: 0.1667 - val_loss: 3.2338 - val_accuracy: 0.1476 - lr: 0.0010\n",
            "Epoch 6/25\n",
            "32/32 [==============================] - 104s 3s/step - loss: 2.6598 - accuracy: 0.1801 - val_loss: 3.2303 - val_accuracy: 0.1528 - lr: 0.0010\n",
            "Epoch 7/25\n",
            "32/32 [==============================] - 103s 3s/step - loss: 2.5048 - accuracy: 0.2016 - val_loss: 3.2393 - val_accuracy: 0.1528 - lr: 0.0010\n",
            "Epoch 8/25\n",
            "32/32 [==============================] - 100s 3s/step - loss: 2.3340 - accuracy: 0.2413 - val_loss: 3.2446 - val_accuracy: 0.1599 - lr: 0.0010\n",
            "Epoch 9/25\n",
            "32/32 [==============================] - 104s 3s/step - loss: 2.1403 - accuracy: 0.2979 - val_loss: 3.2409 - val_accuracy: 0.1630 - lr: 0.0010\n",
            "Epoch 10/25\n",
            "32/32 [==============================] - 104s 3s/step - loss: 1.9738 - accuracy: 0.3603 - val_loss: 3.1894 - val_accuracy: 0.1733 - lr: 2.0000e-04\n",
            "Epoch 11/25\n",
            "32/32 [==============================] - 103s 3s/step - loss: 1.9028 - accuracy: 0.3863 - val_loss: 3.1945 - val_accuracy: 0.1725 - lr: 2.0000e-04\n",
            "Epoch 12/25\n",
            "32/32 [==============================] - 102s 3s/step - loss: 1.8461 - accuracy: 0.4139 - val_loss: 3.1925 - val_accuracy: 0.1753 - lr: 2.0000e-04\n",
            "Epoch 13/25\n",
            "32/32 [==============================] - 104s 3s/step - loss: 1.7851 - accuracy: 0.4364 - val_loss: 3.1936 - val_accuracy: 0.1765 - lr: 2.0000e-04\n",
            "Epoch 14/25\n",
            "32/32 [==============================] - 103s 3s/step - loss: 1.7376 - accuracy: 0.4555 - val_loss: 3.1942 - val_accuracy: 0.1769 - lr: 4.0000e-05\n",
            "Epoch 15/25\n",
            "32/32 [==============================] - 101s 3s/step - loss: 1.7233 - accuracy: 0.4623 - val_loss: 3.1952 - val_accuracy: 0.1769 - lr: 4.0000e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7e9069098a60>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "# Reduce the number of layers\n",
        "num_layers = 2\n",
        "# Reduce the number of attention heads\n",
        "num_heads = 2\n",
        "# Training model\n",
        "transformer.fit(train_ds,\n",
        "                epochs = 25,\n",
        "                validation_data = val_ds,\n",
        "                callbacks = [early_stopping,\n",
        "                             reduce_lr])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "d8093bf9",
      "metadata": {
        "id": "d8093bf9"
      },
      "outputs": [],
      "source": [
        "# Saving weights of model\n",
        "transformer.save_weights(\"eng-hin.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "2Lk25oVSQ_t4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Lk25oVSQ_t4",
        "outputId": "3c3166fb-f2b5-4469-e1bb-00e65d6c305c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "english_sent:  Programme for Promoting People's Awareness\n",
            "Translated Sentence :  यो एउटा त्रुटि       ।     \n"
          ]
        }
      ],
      "source": [
        "# Sample for testing\n",
        "eng = \"This is an error\"\n",
        "print(\"english_sent: \",eng)\n",
        "print(\"Translated Sentence : \",decode_sequence(eng))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculating BLEU Score for Test Data\n",
        "In this section, we calculate the BLEU score for the test data to evaluate the quality of the translated Nepali sentences compared to the original."
      ],
      "metadata": {
        "id": "bU_QZldYoDJg"
      },
      "id": "bU_QZldYoDJg"
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "4E7It5I1Q_5M",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4E7It5I1Q_5M",
        "outputId": "8a15ce3b-4092-495b-aa5c-527bf289d67d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU score is :  0.00878851258127425\n"
          ]
        }
      ],
      "source": [
        "# Calculating BLEU score for test data\n",
        "eng = test[\"english_sent\"].values\n",
        "original = test[\"nepali_sent\"].values\n",
        "translated = [decode_sequence(sent) for sent in eng]\n",
        "bleu = 0\n",
        "\n",
        "for i in range(test.shape[0]):\n",
        "    bleu += sentence_bleu([original[i].split()], translated[i].split(), weights = (0.5, 0.5))\n",
        "\n",
        "print(\"BLEU score is : \", bleu / test.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculating METEOR Score for Sentence Evaluation\n",
        "Setup and Imports\n",
        "Ensure you have downloaded the required NLTK resource for WordNet before proceeding."
      ],
      "metadata": {
        "id": "SOGDFMCCoPd4"
      },
      "id": "SOGDFMCCoPd4"
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "# Uncomment the line below and run it once to download the WordNet resource\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Now you can import meteor_score\n",
        "from nltk.translate import meteor_score\n",
        "\n",
        "# Your reference and hypothesis sentences\n",
        "reference = \"This is the reference sentence.\"\n",
        "hypothesis = \"This is the hypothesis sentence.\"\n",
        "\n",
        "# Tokenize sentences into words\n",
        "ref_tokens = reference.split()\n",
        "hyp_tokens = hypothesis.split()\n",
        "\n",
        "# Calculate METEOR score\n",
        "score = meteor_score.meteor_score([ref_tokens], hyp_tokens)\n",
        "\n",
        "print(\"METEOR Score:\",score)"
      ],
      "metadata": {
        "id": "4T0wq45gyx6m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92e47379-bb64-49ad-9c0d-54a4cd2cb857"
      },
      "id": "4T0wq45gyx6m",
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "METEOR Score: 0.7500000000000001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacrebleu\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8ZOt1YnWh8m",
        "outputId": "dc0394e6-af05-450a-debc-0bec5d43eec5"
      },
      "id": "-8ZOt1YnWh8m",
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (2.4.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2.10.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2024.5.15)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.25.2)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculating BLEU Score using SacreBLEU\n",
        "Imports and Loading Data\n",
        "Import necessary libraries and load your reference and test data from CSV files using Pandas."
      ],
      "metadata": {
        "id": "YBWjpjFtodfS"
      },
      "id": "YBWjpjFtodfS"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import sacrebleu\n",
        "\n",
        "# Load CSV files into Pandas DataFrames\n",
        "reference_df = pd.read_csv('/content/train.csv')\n",
        "test_df = pd.read_csv('/content/test.csv')\n",
        "\n",
        "# Assuming your CSV files have a column named 'sentence' for the sentences\n",
        "reference_sentences = reference_df['english_sent'].tolist()\n",
        "test_sentences = test_df['nepali_sent'].tolist()\n",
        "\n",
        "# Combine reference sentences into a list of lists (as sacrebleu expects multiple references)\n",
        "references = [[ref] for ref in reference_sentences]\n",
        "\n",
        "# Calculate BLEU score using sacrebleu\n",
        "bleu = sacrebleu.corpus_bleu(test_sentences, references)\n",
        "\n",
        "print(f\"BLEU Score: {bleu.score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lMrwqs6mAe5",
        "outputId": "d22567ec-ac23-4ffe-b0a3-ea67e23e7296"
      },
      "id": "3lMrwqs6mAe5",
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score: 1.9146030690102511\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}